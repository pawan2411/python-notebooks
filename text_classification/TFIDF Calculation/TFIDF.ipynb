{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Text Data for Machine Learning with scikit-learn\n",
    "\n",
    "__Text data requires special preparation before you can start using it for predictive modeling.__\n",
    "\n",
    "The text must be parsed to extract words (tokens), called tokenization. \n",
    "Then the words need to be encoded as integers or floating point values which will be passed as an input to a machine learning algorithm, the process is called as feature extraction (or vectorization).\n",
    "\n",
    "The scikit-learn library offers easy-to-use tools to perform both tokenization and feature extraction from your text data.\n",
    "\n",
    "In this activity, you will discover exactly how you can prepare your text data for predictive modeling in Python with scikit-learn.\n",
    "- How to convert text to word frequency vectors with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Explanation:\n",
    "\n",
    "\n",
    "\n",
    "    TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:\n",
    "\n",
    "    TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "    IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:\n",
    "\n",
    "    IDF(t) = log_e(Total number of documents / Number of documents with term t in it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time flies like an arrow. \n",
      "Fruit flies like a banana. \n",
      "Sam sat on the cat.\n",
      "The cat is a b c d e white.\n"
     ]
    }
   ],
   "source": [
    "data = '''Time flies like an arrow. \n",
    "Fruit flies like a banana. \n",
    "Sam sat on the cat.\n",
    "The cat is a b c d e white.'''\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider each sentence as a document. Split the data into sentences based on new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time flies like an arrow. ',\n",
       " 'Fruit flies like a banana. ',\n",
       " 'Sam sat on the cat.',\n",
       " 'The cat is a b c d e white.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data.split('\\n')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "\n",
    "\n",
    "The most popular method is called TF-IDF. This is an acronym than stands for “Term Frequency – Inverse Document Frequency\" which are the components of the resulting scores assigned to each word.\n",
    "\n",
    "- Term Frequency: This summarizes how often a given word appears within a document.\n",
    "- Inverse Document Frequency: This downscale words that appear a lot across documents.\n",
    "\n",
    "TF-IDF are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents.\n",
    "\n",
    "The TfidfVectorizer will tokenize documents, learn the vocabulary and inverse document frequency weightings, and allow you to encode new documents. \n",
    "\n",
    "Below is an example of using the TfidfVectorizer to learn vocabulary and inverse document frequencies across 4 small documents and then encode one of those documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 1)\t0.4854606118156975\n",
      "  (0, 0)\t0.4854606118156975\n",
      "  (0, 7)\t0.3827427224171519\n",
      "  (0, 4)\t0.3827427224171519\n",
      "  (0, 12)\t0.4854606118156975\n",
      "  (1, 2)\t0.5552826649411127\n",
      "  (1, 5)\t0.5552826649411127\n",
      "  (1, 7)\t0.43779123108611473\n",
      "  (1, 4)\t0.43779123108611473\n",
      "  (2, 3)\t0.3827427224171519\n",
      "  (2, 11)\t0.3827427224171519\n",
      "  (2, 8)\t0.4854606118156975\n",
      "  (2, 10)\t0.4854606118156975\n",
      "  (2, 9)\t0.4854606118156975\n",
      "  (3, 13)\t0.5552826649411127\n",
      "  (3, 6)\t0.5552826649411127\n",
      "  (3, 3)\t0.43779123108611473\n",
      "  (3, 11)\t0.43779123108611473\n"
     ]
    }
   ],
   "source": [
    "# sklearn.feature_extraction.text.TfidfVectorizer - Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "# idfs are calculated by TfidfTransformer's fit()\n",
    "# tfidfs are calculated by TfidfTransformer's transform()\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1), lowercase = False) # stop_words='english'\n",
    "tfidf = tfidf_vectorizer.fit_transform(dataset)  \n",
    "print(type(tfidf))\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time flies like an arrow. ',\n",
       " 'Fruit flies like a banana. ',\n",
       " 'Sam sat on the cat.',\n",
       " 'The cat is a b c d e white.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the 4 documents are encoded as 14-element sparse array and we can review the final scorings of each word with different values for the words in the vocabulary.\n",
    "\n",
    "The scores are normalized to values between 0 and 1 and the encoded document vectors can then be used directly with machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write tfidf as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "['an', 'arrow', 'banana', 'cat', 'flies', 'fruit', 'is', 'like', 'on', 'sam', 'sat', 'the', 'time', 'white']\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print(len(feature_names))\n",
    "print(feature_names,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time flies like an arrow. ',\n",
       " 'Fruit flies like a banana. ',\n",
       " 'Sam sat on the cat.',\n",
       " 'The cat is white.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48546061 0.48546061 0.         0.         0.38274272 0.\n",
      "  0.         0.38274272 0.         0.         0.         0.\n",
      "  0.48546061 0.        ]\n",
      " [0.         0.         0.55528266 0.         0.43779123 0.55528266\n",
      "  0.         0.43779123 0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.38274272 0.         0.\n",
      "  0.         0.         0.48546061 0.48546061 0.48546061 0.38274272\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.43779123 0.         0.\n",
      "  0.55528266 0.         0.         0.         0.         0.43779123\n",
      "  0.         0.55528266]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>arrow</th>\n",
       "      <th>banana</th>\n",
       "      <th>cat</th>\n",
       "      <th>flies</th>\n",
       "      <th>fruit</th>\n",
       "      <th>is</th>\n",
       "      <th>like</th>\n",
       "      <th>on</th>\n",
       "      <th>sam</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "      <th>time</th>\n",
       "      <th>white</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.485461</td>\n",
       "      <td>0.485461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Time flies like an arrow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437791</td>\n",
       "      <td>0.555283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruit flies like a banana.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485461</td>\n",
       "      <td>0.485461</td>\n",
       "      <td>0.485461</td>\n",
       "      <td>0.382743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Sam sat on the cat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555283</td>\n",
       "      <td>The cat is white.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         an     arrow    banana       cat     flies     fruit        is  \\\n",
       "0  0.485461  0.485461  0.000000  0.000000  0.382743  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.555283  0.000000  0.437791  0.555283  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.382743  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.437791  0.000000  0.000000  0.555283   \n",
       "\n",
       "       like        on       sam       sat       the      time     white  \\\n",
       "0  0.382743  0.000000  0.000000  0.000000  0.000000  0.485461  0.000000   \n",
       "1  0.437791  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.485461  0.485461  0.485461  0.382743  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.437791  0.000000  0.555283   \n",
       "\n",
       "                          text  \n",
       "0   Time flies like an arrow.   \n",
       "1  Fruit flies like a banana.   \n",
       "2          Sam sat on the cat.  \n",
       "3            The cat is white.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df= pd.DataFrame(tfidf.toarray(), columns= tfidf_vectorizer.get_feature_names()) # Array mapping from feature integer indices to feature names\n",
    "text_df['text'] = dataset\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.4854606118156975\n",
      "  (0, 0)\t0.4854606118156975\n",
      "  (0, 7)\t0.3827427224171519\n",
      "  (0, 4)\t0.3827427224171519\n",
      "  (0, 12)\t0.4854606118156975\n",
      "  (1, 2)\t0.5552826649411127\n",
      "  (1, 5)\t0.5552826649411127\n",
      "  (1, 7)\t0.43779123108611473\n",
      "  (1, 4)\t0.43779123108611473\n",
      "  (2, 3)\t0.3827427224171519\n",
      "  (2, 11)\t0.3827427224171519\n",
      "  (2, 8)\t0.4854606118156975\n",
      "  (2, 10)\t0.4854606118156975\n",
      "  (2, 9)\t0.4854606118156975\n",
      "  (3, 13)\t0.5552826649411127\n",
      "  (3, 6)\t0.5552826649411127\n",
      "  (3, 3)\t0.43779123108611473\n",
      "  (3, 11)\t0.43779123108611473\n"
     ]
    }
   ],
   "source": [
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reference__: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
